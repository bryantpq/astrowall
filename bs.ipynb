{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "TODO:\n",
    "Add compatibility for Windows\n",
    "In filter_links, need to consider that it might not be actual image, imgur has the image embedded in some html usually\n",
    "Figure out how to show x number of reddit posts\n",
    "\n",
    "NOTES:\n",
    "- Selenium is only necessary for scraping the new reddit, since it is heavily-javascript driven,\n",
    "      requests library is sufficient if scraping from the old reddit instead\n",
    "- Selenium is used to scrape and BeautifulSoup used to parse\n",
    "- Headless Chrome driver is used to render html from javascript without actually opening up a browser window\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def astrowall():\n",
    "    status, folder = gen_folder()\n",
    "\n",
    "    print(\"Scraping...\" if status else \"You already scraped today.\")\n",
    "\n",
    "    if status:\n",
    "        anchors  = scrapity_scroopity()\n",
    "        img_urls = filter_anchors(anchors)\n",
    "        save_imgs(img_urls)\n",
    "        \n",
    "    print(\"Changing wallpaper...\")\n",
    "    set_wall(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_folder():\n",
    "    '''\n",
    "    Returns tuple of true if the folder of the week already exists and the folder name.\n",
    "    '''\n",
    "    import datetime as dt\n",
    "    import os\n",
    "    \n",
    "    PIC_PATH = \"pictures/\"\n",
    "    os.chdir(PIC_PATH)\n",
    "    status = True\n",
    "    \n",
    "    if not os.path.isdir(dt.date.today().strftime(\"%d%m%Y\")):\n",
    "        status = False\n",
    "        os.makedirs(new_folder)\n",
    "    \n",
    "    return status, new_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrapity_scroopity():\n",
    "    '''\n",
    "    Show me the query\n",
    "    or just return a list of anchor tags for each reddit post.\n",
    "    \n",
    "    Notes:\n",
    "    https://www.analyticsvidhya.com/blog/2015/10/beginner-guide-web-scraping-beautiful-soup-python/\n",
    "    '''\n",
    "    from selenium import webdriver\n",
    "    from selenium.webdriver.chrome.options import Options\n",
    "    from bs4 import BeautifulSoup\n",
    "    \n",
    "    chrome_options = Options()  \n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    \n",
    "    vroom = webdriver.Chrome(chrome_options=chrome_options)\n",
    "    vroom.get(\"https://old.reddit.com/r/spaceporn/top/?sort=top&t=week\")\n",
    "    soup = BeautifulSoup(d.page_source)\n",
    "    \n",
    "    return soup.find_all('a', {'data-event-action': 'title', 'class': 'title may-blank outbound'})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_anchors(anchors):\n",
    "    '''\n",
    "    Parse the given list of anchor tags and return a list of anchors satisfying the aspect ratio.\n",
    "    Accepted format for urls:\n",
    "    <a \n",
    "        class=\"title may-blank outbound\"\n",
    "        data-event-action=\"title\"\n",
    "        data-href-url=\"https://cdn.eso.org/images/large/eso0905a.jpg\"\n",
    "        data-outbound-expiration=\"1533102938000\"\n",
    "        data-outbound-url=\"https://out.reddit.com/t3_9275r8?url=https%3A%2F%2Fcdn.eso.org%2Fimages%2Flarge%2Feso0905a.jpg&amp;token=AQAAWkthW-Ra4RKuGOx6IaqdaZiZUMjz6Kn_8Urgsdp-m5Sfo6cF&amp;app_name=reddit.com\" \n",
    "        href=\"https://cdn.eso.org/images/large/eso0905a.jpg\" \n",
    "        rel=\"\" tabindex=\"1\">The Carina Nebula [8408 x 8337]\n",
    "    </a>\n",
    "    \n",
    "    Notes:\n",
    "    https://askubuntu.com/questions/584688/how-can-i-get-the-monitor-resolution-using-the-command-line\n",
    "    http://rubular.com/\n",
    "    '''\n",
    "    import re\n",
    "    #from constants import DEFAULT, TOL\n",
    "    DEFAULT = 1.7\n",
    "    TOL = 0.1\n",
    "    anc_pass = []\n",
    "\n",
    "    for anc in anchors:\n",
    "        res = re.search('\\d{4}\\s*[x]\\s*\\d{4}', str(anc))\n",
    "        if res:\n",
    "            # check aspect ratio of pic\n",
    "            w = int(res.group()[:4])\n",
    "            h = int(res.group()[-4:])\n",
    "            if abs(DEFAULT - w / h) < TOL:\n",
    "                anc_pass.append(anc)\n",
    "    \n",
    "    return anc_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_links(anchors):\n",
    "    '''\n",
    "    Given a list of anchors that pass the aspect ratio test, extract their image urls to be downloaded.\n",
    "    Note that imgur sometimes has the image embedded within some html.\n",
    "    \n",
    "    Using requests lib just to check header content because selenium is unable to do so.\n",
    "    '''\n",
    "    from requests import get\n",
    "    from selenium import webdriver\n",
    "    from selenium.webdriver.chrome.options import Options\n",
    "    from bs4 import BeautifulSoup\n",
    "    \n",
    "    img_pass = []\n",
    "    for anc in anchors:\n",
    "        response = get(anc['data-href-url'])\n",
    "        if \"image\" in response.headers['Content-Type']:\n",
    "            img_pass.append(response.headers['Content-Type'])\n",
    "        elif \"imgur.com/\" in anc['data-href-url']: # make a better check than this\n",
    "            # support more image hosting sites?                \n",
    "            # use selenium here\n",
    "            chrome_options = Options()\n",
    "            chrome_options.add_argument(\"--headless\")\n",
    "            driver = webdriver.Chrome(chrome_options = chrome_options)\n",
    "            driver.get(anc['data-href-url'])\n",
    "\n",
    "            url = driver.find_element_by_css_selector('.image.post-image').find_element_by_tag_name('img').get_attribute('src')\n",
    "            img_pass.append(url)\n",
    "\n",
    "    return img_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_imgs(urls):\n",
    "    import shutil\n",
    "    import requests\n",
    "    \n",
    "    for i, url in enumerate(urls, 1):\n",
    "        response = requests.get(url, stream=True)\n",
    "        with open('img{}.png'.format(i), 'wb') as out_file:\n",
    "            shutil.copyfileobj(response.raw, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_wall(folder):\n",
    "    '''\n",
    "    Selects and assigns a random wallpaper from the given folder.\n",
    "    \n",
    "    Notes:\n",
    "    https://askubuntu.com/questions/66914/how-to-change-desktop-background-from-command-line-in-unity\n",
    "    '''\n",
    "    import os\n",
    "    import subprocess as sp\n",
    "    from random import choice\n",
    "    \n",
    "    os.chdir(folder)\n",
    "    wall = choice(os.listdir())\n",
    "    try:\n",
    "        sp.check_output(['gsettings', 'set', 'org.gnome.desktop.background', 'picture-uri', 'file://{}'.format(wall)])\n",
    "    except sp.CalledProcessError as e:\n",
    "        print(\"An error occured while trying to change your wallpaper.\\n\"\n",
    "             \"Please ensure you have 'gsettings' installed.\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
